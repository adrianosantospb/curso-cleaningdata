{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise e Transformação de Variáveis Qualitativas\n",
    "#### Por Adriano Santos\n",
    "\n",
    "Neste seguimento iremos analisar e, se necessário, transformar as variáveis qualitativas de nosso *dataset*. Por que devemos analisar e, se possível transformar essas variáveis?\n",
    "\n",
    "Então... nós temos dois tipos de variáveis qualitativas: a) nominais e b) ordinais. Como o próprio nome já diz, a primeira são nomes e não expressam escalas. Por exemplo: uma variável (ou dimensão, como prefiro chamar) chamada de **cores** (variável nominal) possui as opções: preta, branca, amarela, azul etc. Por mais que você tenha uma cor preferida, em efeitos práticos e gerais, não significa dizer que ela tenha maior importância do que as demais cores - todas possuem o mesmo nível de importância. No entanto, quando a nossa variável é do tipo ordinal, a ordem faz diferença.\n",
    "\n",
    "Imagine que você esteja se referindo ao tamanho de camisas (PP, P, M, G, GG, XG...). A ordem desses valores faz completa diferença para a nossa análise, porque: P > PP; M > P; etc. Quando temos uma variável qualitativa, podemos realizar algumas ações para melhorar a performance do nosso algoritmo. Porém, os procedimentos devem ser diferentes para as variáveis qualitativas nominais e para as ordinais. \n",
    "\n",
    "Vamos lá! Perceba que iremos repetir várias das etapas anteriores. Isso deve ser encarado como algo padrão. Então, você deve ter em mente que atividades como carregar os dados, analisar as estruturas, tratar *data missing* etc. fazem parte de quase todas as suas análises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import pandas as pd\n",
    "\n",
    "# Parâmetro referente aos dataframes (https://stackoverflow.com/questions/21463589/pandas-chained-assignments)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Carregando a estrutura do *dataset*\n",
    "\n",
    "Nós já conhecemos esse procedimento. Lembre-se que nós o fizemos no exemplo anterior. Sendo assim, irei supor que você se lembre de como foi feito e que você o repetirá aqui. Aconselho que você nunca copie o texto ou o comando, mas que sempre digite. Isso fará com que você memorize e aprenda de verdade a cada passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parlamentar</th>\n",
       "      <th>idecadastro</th>\n",
       "      <th>nuCarteiraParlamentar</th>\n",
       "      <th>nuLegislatura</th>\n",
       "      <th>sgUF</th>\n",
       "      <th>sgPartido</th>\n",
       "      <th>codLegislatura</th>\n",
       "      <th>numSubCota</th>\n",
       "      <th>txtDescricao</th>\n",
       "      <th>numEspecificacaoSubCota</th>\n",
       "      <th>...</th>\n",
       "      <th>numMes</th>\n",
       "      <th>numAno</th>\n",
       "      <th>numParcela</th>\n",
       "      <th>txtPassageiro</th>\n",
       "      <th>txtTrecho</th>\n",
       "      <th>numLote</th>\n",
       "      <th>numRessarcimento</th>\n",
       "      <th>vlrRestituicao</th>\n",
       "      <th>nuDeputadoId</th>\n",
       "      <th>ideDocumento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>178957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1471159.0</td>\n",
       "      <td>6192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6519085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>178957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1497012.0</td>\n",
       "      <td>6289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6586329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>178957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1471173.0</td>\n",
       "      <td>6192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6519234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>178957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483154.0</td>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6549679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>178957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1463325.0</td>\n",
       "      <td>6139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>6498316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parlamentar  idecadastro nuCarteiraParlamentar  nuLegislatura sgUF  \\\n",
       "0  ABEL MESQUITA JR.     178957.0                     1         2015.0   RR   \n",
       "1  ABEL MESQUITA JR.     178957.0                     1         2015.0   RR   \n",
       "2  ABEL MESQUITA JR.     178957.0                     1         2015.0   RR   \n",
       "3  ABEL MESQUITA JR.     178957.0                     1         2015.0   RR   \n",
       "4  ABEL MESQUITA JR.     178957.0                     1         2015.0   RR   \n",
       "\n",
       "  sgPartido  codLegislatura  numSubCota                   txtDescricao  \\\n",
       "0       DEM            55.0         3.0  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "1       DEM            55.0         3.0  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "2       DEM            55.0         3.0  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "3       DEM            55.0         3.0  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "4       DEM            55.0         3.0  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "\n",
       "   numEspecificacaoSubCota      ...      numMes  numAno numParcela  \\\n",
       "0                      1.0      ...         2.0  2018.0        0.0   \n",
       "1                      1.0      ...         4.0  2018.0        0.0   \n",
       "2                      1.0      ...         3.0  2018.0        0.0   \n",
       "3                      1.0      ...         3.0  2018.0        0.0   \n",
       "4                      1.0      ...         1.0  2018.0        0.0   \n",
       "\n",
       "  txtPassageiro  txtTrecho    numLote  numRessarcimento  vlrRestituicao  \\\n",
       "0           NaN        NaN  1471159.0            6192.0             0.0   \n",
       "1           NaN        NaN  1497012.0            6289.0             0.0   \n",
       "2           NaN        NaN  1471173.0            6192.0             0.0   \n",
       "3           NaN        NaN  1483154.0            6238.0             0.0   \n",
       "4           NaN        NaN  1463325.0            6139.0             0.0   \n",
       "\n",
       "   nuDeputadoId  ideDocumento  \n",
       "0        3074.0     6519085.0  \n",
       "1        3074.0     6586329.0  \n",
       "2        3074.0     6519234.0  \n",
       "3        3074.0     6549679.0  \n",
       "4        3074.0     6498316.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrangando os dados\n",
    "df = pd.read_csv('dados/deputados.csv', delimiter=';', low_memory=False)\n",
    "# Visualiza os 5 primeiros registros do dataset. \n",
    "df.rename({'txNomeParlamentar ':'parlamentar'}, axis='columns', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168380 entries, 0 to 168379\n",
      "Data columns (total 29 columns):\n",
      "parlamentar                  168380 non-null object\n",
      "idecadastro                  167895 non-null float64\n",
      "nuCarteiraParlamentar        167894 non-null object\n",
      "nuLegislatura                168379 non-null float64\n",
      "sgUF                         167894 non-null object\n",
      "sgPartido                    167894 non-null object\n",
      "codLegislatura               167894 non-null float64\n",
      "numSubCota                   168379 non-null float64\n",
      "txtDescricao                 168379 non-null object\n",
      "numEspecificacaoSubCota      168378 non-null float64\n",
      "txtDescricaoEspecificacao    40373 non-null object\n",
      "txtFornecedor                168379 non-null object\n",
      "txtCNPJCPF                   155428 non-null object\n",
      "txtNumero                    166796 non-null object\n",
      "indTipoDocumento             168376 non-null float64\n",
      "datEmissao                   166796 non-null object\n",
      "vlrDocumento                 168375 non-null float64\n",
      "vlrGlosa                     168375 non-null float64\n",
      "vlrLiquido                   168375 non-null float64\n",
      "numMes                       168375 non-null float64\n",
      "numAno                       168375 non-null float64\n",
      "numParcela                   168375 non-null float64\n",
      "txtPassageiro                48438 non-null object\n",
      "txtTrecho                    48220 non-null object\n",
      "numLote                      168375 non-null float64\n",
      "numRessarcimento             168362 non-null float64\n",
      "vlrRestituicao               168375 non-null float64\n",
      "nuDeputadoId                 168375 non-null float64\n",
      "ideDocumento                 168375 non-null float64\n",
      "dtypes: float64(17), object(12)\n",
      "memory usage: 37.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Analisando as informações do dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Iniciando procedimentos de análise e transformação\n",
    "\n",
    "Antes de qualquer coisa, iremos reduzir as dimensões do nosso *dataset*. Não utilizaremos aqui nenhuma técnica especial para a redução das dimensões. Selecionaremos apenas algumas dimensões para que as técnicas que são foco do presente capítulo sejam aplicadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parlamentar</th>\n",
       "      <th>sgUF</th>\n",
       "      <th>sgPartido</th>\n",
       "      <th>txtDescricao</th>\n",
       "      <th>vlrDocumento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1492.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1474.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABEL MESQUITA JR.</td>\n",
       "      <td>RR</td>\n",
       "      <td>DEM</td>\n",
       "      <td>COMBUSTÍVEIS E LUBRIFICANTES.</td>\n",
       "      <td>1513.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         parlamentar sgUF sgPartido                   txtDescricao  \\\n",
       "0  ABEL MESQUITA JR.   RR       DEM  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "1  ABEL MESQUITA JR.   RR       DEM  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "2  ABEL MESQUITA JR.   RR       DEM  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "3  ABEL MESQUITA JR.   RR       DEM  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "4  ABEL MESQUITA JR.   RR       DEM  COMBUSTÍVEIS E LUBRIFICANTES.   \n",
       "\n",
       "   vlrDocumento  \n",
       "0         70.00  \n",
       "1        200.00  \n",
       "2       1492.81  \n",
       "3       1474.33  \n",
       "4       1513.82  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando se existe alguma dimensão do dataset com dados faltantes. \n",
    "df_reduzido = df[[\"parlamentar\", \"sgUF\", \"sgPartido\", \"txtDescricao\", \"vlrDocumento\"]]\n",
    "df_reduzido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as instâncias que possuem missing values\n",
    "df_reduzido.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Transformando os dados\n",
    "\n",
    "Agora, iremos transformar as dimensões nominais em representações numéricas. Utilizaremos o módulo *LabelEncoder* do **Sckit-learn**. Por que isso é importante? Por dois motivos: além de ajudar na melhoria/desempenho do processamento das informações, ele evita o viés. Sim. O viés. \n",
    "\n",
    "Por exemplo: em nosso *dataset* temos uma dimensão com os nomes dos candidatos. Se desejarmos analisar, por exemplo, os gastos desses ou até mesmo realizar alguma análise mais aprofundada, idealmente devemos remover ou ocultar o nome dos participantes das pesquisas. Isso é padrão: não devemos usar os nomes das pessoas em nossas pesquisas, exceto que desejemos analisar a participação específica desses.\n",
    "\n",
    "Vamos lá! Perceba que iremos repetir várias das etapas anteriores. Isso deve ser encarado como algo padrão. Então, você deve ter em mente que atividades como carregar os dados, analisar as estruturas, tratar *data missing* etc. fazem parte de quase todas as suas análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parlamentar</th>\n",
       "      <th>sgUF</th>\n",
       "      <th>sgPartido</th>\n",
       "      <th>txtDescricao</th>\n",
       "      <th>vlrDocumento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1492.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1474.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1513.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parlamentar  sgUF  sgPartido  txtDescricao  vlrDocumento\n",
       "0          110    14         11            10         70.00\n",
       "1          110    14         11            10        200.00\n",
       "2          110    14         11            10       1492.81\n",
       "3          110    14         11            10       1474.33\n",
       "4          110    14         11            10       1513.82"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando a biblioteca \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instanciando o objeto\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Transformações\n",
    "df_reduzido.sgPartido = le.fit_transform(df_reduzido.sgPartido.astype(str))\n",
    "df_reduzido.sgUF = le.fit_transform(df_reduzido.sgUF.astype(str))\n",
    "df_reduzido.txtDescricao = le.fit_transform(df_reduzido.txtDescricao.astype(str))\n",
    "df_reduzido.parlamentar = le.fit_transform(df_reduzido.parlamentar.astype(str))\n",
    "\n",
    "# Visualizando os dados\n",
    "df_reduzido.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok... até aqui, tudo bem. Mas perceba o seguinte: os valores nominais foram convertidos para valores numéricos. Porém, isso nos gera um novo problema. O que significa o valor 2 na dimensão parlamentar, por exemplo? O valor 2 é maior do que o valor 1? Sabemos que, neste caso, não - e em todos os casos presentes em nosso *dataset*. Sendo assim, precisaremos realizar um procedimento conhecido como *Dummy Coding*. \n",
    "\n",
    "O *Dummy Coding* fará com que as classes (ex: branca, preta, amarela ...) de cada dimensão se torne uma nova dimensão e que receberão valores 0 ou 1 para indicar a ausência ou presença de um valor. Suponha que tenhamos uma dimensão chamada **cor** e os valores das classes são **branca**, **preta** e **vermelha**. Com o procedimento do LabelEncoder, teríamos a conversão dos nomes por números (1, 2 e 3). Porém, quando realizamos o *Dummy Coding*, a dimensão **cor** será substituída por três novas dimensões, que receberão os valores 0 e 1, de acordo com o valor de cada registro. Isso significa dizer que, se a cor preferia de um participante **U** for preta, então a dimensão preta receberá o valor 1 e as demais receberão o valor 0.\n",
    "\n",
    "Por que devemos fazer isso? Quando aplicamos o procedimento de *Dummy Coding* possibilitamos que modelos de predição possam utilizar dos valores das variáveis nominais. Então, vamos lá.\n",
    "\n",
    "Para realizarmos o procedimento de *Dummy Coding* precisaremos importar o módulo **OneHotEncoder** do *sklearn.preprocessing*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando módulo\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Criando objeto\n",
    "dc = OneHotEncoder(categorical_features=[0, 1, 2, 3]) # Os números de 0 a 3 representam as colunas que serão processadas.\n",
    "# Realiza a conversão\n",
    "df_reduzido = dc.fit_transform(df_reduzido).toarray()\n",
    "# Perceba que você não precisou informar quais as dimensões serão transformadas no dataframe. Isso porque já foi definido\n",
    "# no momento que o objeto OneHotEncoder foi instanciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,   70.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,  200.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  , 1492.81],\n",
       "       ...,\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,  685.93],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  ,  202.  ],\n",
       "       [   0.  ,    0.  ,    0.  , ...,    0.  ,    0.  , -128.  ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados\n",
    "df_reduzido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Podemos fazer mais alguma coisa?\n",
    "\n",
    "A resposta a essa pergunta é: depende. :)\n",
    "\n",
    "Uma das atividades que, geralmente, é aplicada nesta etapa do tratamento dos dados é a *Feature scaling* (https://en.wikipedia.org/wiki/Feature_scaling). \n",
    "\n",
    "E o que se ganha com esse procedimento? Desempenho e modelos mais precisos. Ai você pode me perguntar: mas até nas dimensões que foram transformadas? Bem... se você realizar uma pesquisa no **Google** sobre *Feature scaling*, por exemplo, você encontrará vários defensores do seu uso (sim) e do não. Eu diria que depende muito do que se deseja fazer, mas, na maioria dos casos eu aconselho que sim. Bem porque, os dados \"terão aparencia não identificada pelo homem\" e isso evita viés. Bem... avalie, ok? \n",
    "\n",
    "Vamos agora apresentar como você utiliza o módulo **StandardScaler** para realizar o *Feature Scaling*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743, -0.30145366],\n",
       "       [-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743, -0.23993662],\n",
       "       [-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743,  0.37183141],\n",
       "       ...,\n",
       "       [-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743, -0.00999066],\n",
       "       [-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743, -0.2389902 ],\n",
       "       [-0.06330153, -0.0490426 , -0.03698469, ..., -0.03225567,\n",
       "        -0.01242743, -0.39514884]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando módulo\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Instancia o objeto StandardScaler\n",
    "fs = StandardScaler(with_mean=True) # Utilizei a abordagem Mean normalization\n",
    "# Realiza o treinamento\n",
    "df_reduzido = fs.fit_transform(df_reduzido)\n",
    "# Visualizando os dados\n",
    "df_reduzido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você percebeu o que aconteceu com os dados? Não ficaram \"estranhos ao nossos olhos\"? Aos nossos olhos sim, mas não para os algoritmos de *machine learning*. :)\n",
    "\n",
    "Muito bom, pessoal! Aprendemos a realizar várias atividades consideradas como fundamentais para a preparação dos nossos dados. Alguns detalhes deverão ser mais aprofundados ainda, claro. Mas já temos a base.\n",
    "\n",
    "Ainda falta a ação de *splitting data* - que será a nossa última atividade desse curso. Conversaremos mais sobre a atividade de normalização de dados. Aqui, nós normalizamos tudo que tínhamos em nosso *dataset*, porém essa atividade não deve ser realizada em todos os casos analisados.\n",
    "\n",
    "Na nossa próxima (e última) atividade, nós trabalharemos a atividade de *splitting data* que se traduz na atividade de dividir o nosso *dataset* (ou fatiar) em dados de treinamento e testes (e validação), que serão utilizados em nossos modelos de *machine learning*. Também apresentarei quando você deve ou não normalizar a dimensão que se caracteriza como variável dependente para o nosso modelo.\n",
    "\n",
    "### O que aprendemos hoje?\n",
    "\n",
    "* Revisamos como carregar os dados para análise e o processo de análise da estrutura dos dados;\n",
    "* Reduzimos a dimensão do nosso dataset (mesmo que de forma manual);\n",
    "* Aprendemos como analisar e transformar os nossos dados;\n",
    "* Realizamos as atividades de transformação de dados nominas em valores numéricos e, também, a atividade de *Dummy Coding*;\n",
    "* Aprendemos a atividade de normalização dos dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
